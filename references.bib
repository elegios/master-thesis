@article{Kaminski2017,
abstract = {Many programming tasks are dramatically simpler when an appropriate domain-specific language can be used to accomplish them. These languages offer a variety of potential advantages, including programming at a higher level of abstraction, custom analyses specific to the problem domain, and the ability to generate very efficient code. But they also suffer many disadvantages as a result of their implementation techniques. Fully separate languages (such as YACC, or SQL) are quite flexible, but these are distinct monolithic entities and thus we are unable to draw on the features of several in combination to accomplish a single task. That is, we cannot compose their domain-specific features. "Embedded" DSLs (such as parsing combinators) accomplish something like a different language, but are actually implemented simply as libraries within a flexible host language. This approach allows different libraries to be imported and used together, enabling composition, but it is limited in analysis and translation capabilities by the host language they are embedded within. A promising combination of these two approaches is to allow a host language to be directly extended with new features (syntactic and semantic.) However, while there are plausible ways to attempt to compose language extensions, they can easily fail, making this approach unreliable. Previous methods of assuring reliable composition impose onerous restrictions, such as throwing out entirely the ability to introduce new analysis. This thesis introduces reliably composable language extensions as a technique for the implementation of DSLs. This technique preserves most of the advantages of both separate and "embedded" DSLs. Unlike many prior approaches to language extension, this technique ensures composition of multiple language extensions will succeed, and preserves strong properties about the behavior of the resulting composed compiler. We define an analysis on language extensions that guarantees the composition of several extensions will be well-defined, and we further define a set of testable properties that ensure the resulting compiler will behave as expected, along with a principle that assigns "blame" for bugs that may ultimately appear as a result of composition. Finally, to concretely compare our approach to our original goals for reliably composable language extension, we use these techniques to develop an extensible C compiler front-end, together with several example composable language extensions.
},
author = {Kaminski, Ted},
file = {:Users/elegios/Documents/Mendeley Desktop/Kaminski - 2017 - Reliably composable language extensions.pdf:pdf},
title = {{Reliably composable language extensions}},
url = {https://conservancy.umn.edu/handle/11299/188954},
year = {2017}
}
@inproceedings{VanWyk2007,
address = {New York, New York, USA},
author = {{Van Wyk}, Eric R. and Schwerdfeger, August C.},
booktitle = {Proceedings of the 6th international conference on Generative programming and component engineering  - GPCE '07},
doi = {10.1145/1289971.1289983},
file = {:Users/elegios/Documents/Mendeley Desktop/Van Wyk, Schwerdfeger - 2007 - Context-aware scanning for parsing extensible languages.pdf:pdf},
isbn = {9781595938558},
keywords = {context-aware scanning,extensible languages},
pages = {63},
publisher = {ACM Press},
title = {{Context-aware scanning for parsing extensible languages}},
url = {http://portal.acm.org/citation.cfm?doid=1289971.1289983},
year = {2007}
}
@article{VanWyk2010,
author = {{Van Wyk}, Eric and Bodin, Derek and Gao, Jimin and Krishnan, Lijesh},
doi = {10.1016/j.scico.2009.07.004},
file = {:Users/elegios/Documents/Mendeley Desktop/Van Wyk et al. - 2010 - Silver An extensible attribute grammar system.pdf:pdf},
issn = {01676423},
journal = {Science of Computer Programming},
month = {jan},
number = {1-2},
pages = {39--54},
title = {{Silver: An extensible attribute grammar system}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167642309001099},
volume = {75},
year = {2010}
}
@inproceedings{Stansifer2014,
abstract = {Current languages for safely manipulating values with names only support term languages with simple binding syntax. As a result, no tools exist to safely manipulate code written in those languages for which name problems are the most challenging. We address this problem with Romeo, a language that respects $\alpha$-equivalence on its values, and which has access to a rich specification language for binding, inspired by attribute grammars. Our work has the complex-binding support of David Herman's $\lambda$m, but is a full-fledged binding-safe language like Pure FreshML.},
address = {New York, New York, USA},
author = {Stansifer, Paul and Wand, Mitchell},
booktitle = {Proceedings of the 19th ACM SIGPLAN international conference on Functional programming - ICFP '14},
doi = {10.1145/2628136.2628162},
file = {:Users/elegios/Documents/Mendeley Desktop/Stansifer, Wand - 2014 - Romeo.pdf:pdf},
isbn = {9781450328739},
number = {9},
pages = {53--65},
publisher = {ACM Press},
title = {{Romeo}},
url = {http://dl.acm.org/citation.cfm?doid=2628136.2628162},
volume = {49},
year = {2014}
}
@article{Heering1989,
author = {Heering, J. and Hendriks, P. R. H. and Klint, P. and Rekers, J.},
doi = {10.1145/71605.71607},
file = {:Users/elegios/Documents/Mendeley Desktop/Heering et al. - 1989 - The syntax definition formalism SDF---reference manual---.pdf:pdf},
issn = {03621340},
journal = {ACM SIGPLAN Notices},
month = {nov},
number = {11},
pages = {43--75},
publisher = {ACM},
title = {{The syntax definition formalism SDF---reference manual---}},
url = {http://portal.acm.org/citation.cfm?doid=71605.71607},
volume = {24},
year = {1989}
}
@article{Urban2008,
author = {Urban, Christian},
doi = {10.1007/s10817-008-9097-2},
file = {:Users/elegios/Documents/Mendeley Desktop/Urban - 2008 - Nominal Techniques in IsabelleHOL.pdf:pdf},
issn = {0168-7433},
journal = {Journal of Automated Reasoning},
month = {may},
number = {4},
pages = {327--356},
publisher = {Springer Netherlands},
title = {{Nominal Techniques in Isabelle/HOL}},
url = {http://link.springer.com/10.1007/s10817-008-9097-2},
volume = {40},
year = {2008}
}
@inproceedings{Gabbay,
author = {Gabbay, M. and Pitts, A.},
booktitle = {Proceedings. 14th Symposium on Logic in Computer Science (Cat. No. PR00158)},
doi = {10.1109/LICS.1999.782617},
file = {:Users/elegios/Documents/Mendeley Desktop/Gabbay, Pitts - Unknown - A new approach to abstract syntax involving binders.pdf:pdf},
isbn = {0-7695-0158-3},
pages = {214--224},
publisher = {IEEE Comput. Soc},
title = {{A new approach to abstract syntax involving binders}},
url = {http://ieeexplore.ieee.org/document/782617/}
}
@article{Erdweg2013,
abstract = {The theory of context-free languages is well-understood and context-free parsers can be used as off-the-shelf tools in practice. In particular, to use a context-free parser framework, a user does not need to understand its internals but can specify a language declaratively as a grammar. However, many languages in practice are not context-free. One particularly important class of such languages is layout-sensitive languages, in which the structure of code depends on indentation and whitespace. For example, Python, Haskell, F{\#}, and Markdown use indentation instead of curly braces to determine the block structure of code. Their parsers (and lexers) are not declaratively specified but hand-tuned to account for layout-sensitivity. To support declarative specifications of layout-sensitive languages, we propose a parsing framework in which a user can annotate layout in a grammar. Annotations take the form of constraints on the relative positioning of tokens in the parsed subtrees. For example, a user can declare that a block consists of statements that all start on the same column. We have integrated layout constraints into SDF and implemented a layout-sensitive generalized parser as an extension of generalized LR parsing. We evaluate the correctness and performance of our parser by parsing 33 290 open-source Haskell files. Layout-sensitive generalized parsing is easy to use, and its performance overhead compared to layout-insensitive parsing is small enough for practical application.},
author = {Erdweg, Sebastian and Rendel, Tillmann and K{\"{a}}stner, Christian and Ostermann, Klaus},
doi = {10.1007/978-3-642-36089-3_14},
file = {:Users/elegios/Documents/Mendeley Desktop/Erdweg et al. - 2013 - Layout-sensitive generalized parsing.pdf:pdf},
isbn = {9783642360886},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {244--263},
title = {{Layout-sensitive generalized parsing}},
volume = {7745 LNCS},
year = {2013}
}
@inproceedings{Kats2010,
abstract = {Syntax definitions are pervasive in modern software systems, and serve as the basis for language processing tools like parsers and compilers. Mainstream parser generators pose restrictions on syntax definitions that follow from their implementation algorithm. They hamper evolution, maintainability, and compositionality of syntax definitions. The pureness and declarativity of syntax definitions is lost. We analyze how these problems arise for different aspects of syntax definitions, discuss their consequences for language engineers, and show how the pure and declarative nature of syntax definitions can be regained.},
address = {New York, New York, USA},
author = {Kats, Lennart C.L. and Visser, Eelco and Wachsmuth, Guido},
booktitle = {Proceedings of the ACM international conference on Object oriented programming systems languages and applications - OOPSLA '10},
doi = {10.1145/1869459.1869535},
file = {:Users/elegios/Documents/Mendeley Desktop/Kats, Visser, Wachsmuth - 2010 - Pure and declarative syntax definition.pdf:pdf},
isbn = {9781450302036},
pages = {918},
publisher = {ACM Press},
title = {{Pure and declarative syntax definition}},
url = {http://portal.acm.org/citation.cfm?doid=1869459.1869535},
year = {2010}
}
@inproceedings{Lorenzen2016,
abstract = {Syntactic language extensions can introduce new facilities into a programming language while requiring little implementation effort and modest changes to the compiler. It is typical to desugar language extensions in a distinguished compiler phase after parsing or type checking, not affecting any of the later compiler phases. If desugaring happens before type checking, the desugaring cannot depend on typing information and type errors are reported in terms of the generated code. If desugaring happens after type checking, the code generated by the desugaring is not type checked and may introduce vulnerabilities. Both options are undesirable. We propose a system for syntactic extensibility where desugaring happens after type checking and desugarings are guaranteed to only generate well-typed code. A major novelty of our work is that desugarings operate on typing derivations instead of plain syntax trees. This provides desugarings access to typing information and forms the basis for the soundness guarantee we provide, namely that a desugaring generates a valid typing derivation. We have implemented our system for syntactic extensibility in a language-independent fashion and instantiated it for a substantial subset of Java, including generics and inheritance. We provide a sound Java extension for Scala-like for-comprehensions.},
address = {New York, New York, USA},
author = {Lorenzen, Florian and Erdweg, Sebastian},
booktitle = {Proceedings of the 43rd Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages - POPL 2016},
doi = {10.1145/2837614.2837644},
file = {:Users/elegios/Documents/Mendeley Desktop/Lorenzen, Erdweg - 2016 - Sound type-dependent syntactic language extension(2).pdf:pdf},
isbn = {9781450335492},
number = {1},
pages = {204--216},
publisher = {ACM Press},
title = {{Sound type-dependent syntactic language extension}},
url = {http://dl.acm.org/citation.cfm?doid=2837614.2837644},
volume = {51},
year = {2016}
}
@incollection{VanWyk2002,
author = {{Van Wyk}, Eric and de Moor, Oege and Backhouse, Kevin and Kwiatkowski, Paul},
doi = {10.1007/3-540-45937-5_11},
file = {:Users/elegios/Documents/Mendeley Desktop/Van Wyk et al. - 2002 - Forwarding in Attribute Grammars for Modular Language Design.pdf:pdf},
pages = {128--142},
publisher = {Springer, Berlin, Heidelberg},
title = {{Forwarding in Attribute Grammars for Modular Language Design}},
url = {http://link.springer.com/10.1007/3-540-45937-5{\_}11},
year = {2002}
}
@article{Adams1991,
author = {Adams, S.R.},
file = {:Users/elegios/Documents/Mendeley Desktop/Adams - 1991 - Modular grammars for programming language prototyping.pdf:pdf},
journal = {Language},
number = {March},
title = {{Modular grammars for programming language prototyping}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.48.3355{\&}rep=rep1{\&}type=pdf},
year = {1991}
}
@inproceedings{Ford2002,
abstract = {Packrat parsing is a novel technique for implementing parsers in a lazy functional programming language. A packrat parser provides the power and flexibility of top-down parsing with backtracking and unlimited lookahead, but nevertheless guarantees linear parse time. Any language defined by an LL(k) or LR(k) grammar can be recognized by a packrat parser, in addition to many languages that conventional linear-time algorithms do not support. This additional power simplifies the handling of common syntactic idioms such as the widespread but troublesome longest-match rule, enables the use of sophisticated disambiguation strategies such as syntactic and semantic predicates, provides better grammar composition properties, and allows lexical analysis to be integrated seamlessly into parsing. Yet despite its power, packrat parsing shares the same simplicity and elegance as recursive descent parsing; in fact converting a backtracking recursive descent parser into a linear-time packrat parser often involves only a fairly straightforward structural change. This paper describes packrat parsing informally with emphasis on its use in practical applications, and explores its advantages and disadvantages with respect to the more conventional alternatives.},
address = {New York, New York, USA},
author = {Ford, Bryan},
booktitle = {Proceedings of the seventh ACM SIGPLAN international conference on Functional programming - ICFP '02},
doi = {10.1145/581478.581483},
file = {:Users/elegios/Documents/Mendeley Desktop/Ford - 2002 - Packrat parsing simple, powerful, lazy, linear time, functional pearl.pdf:pdf},
isbn = {1581134878},
number = {9},
pages = {36--47},
publisher = {ACM Press},
title = {{Packrat parsing:: simple, powerful, lazy, linear time, functional pearl}},
url = {http://portal.acm.org/citation.cfm?doid=581478.581483},
volume = {37},
year = {2002}
}
@inproceedings{Day2014,
address = {New York, New York, USA},
author = {Day, Laurence E. and Hutton, Graham},
booktitle = {Proceedings of the 25th symposium on Implementation and Application of Functional Languages - IFL '13},
doi = {10.1145/2620678.2620680},
file = {:Users/elegios/Documents/Mendeley Desktop/Day, Hutton - 2014 - Compilation {\`{a}} la Carte.pdf:pdf},
isbn = {9781450329880},
keywords = {catamorphisms,compilation,modularity,monads},
pages = {13--24},
publisher = {ACM Press},
title = {{Compilation {\`{a}} la Carte}},
url = {http://dl.acm.org/citation.cfm?doid=2620678.2620680},
year = {2014}
}
@inproceedings{Pientka2008,
address = {New York, New York, USA},
author = {Pientka, Brigitte},
booktitle = {Proceedings of the 35th annual ACM SIGPLAN-SIGACT symposium on Principles of programming languages - POPL '08},
doi = {10.1145/1328438.1328483},
file = {:Users/elegios/Documents/Mendeley Desktop/Pientka - 2008 - A type-theoretic foundation for programming with higher-order abstract syntax and first-class substitutions(2).pdf:pdf},
isbn = {9781595936899},
issn = {0362-1340},
keywords = {logical frameworks,type system},
number = {1},
pages = {371},
publisher = {ACM Press},
title = {{A type-theoretic foundation for programming with higher-order abstract syntax and first-class substitutions}},
url = {http://portal.acm.org/citation.cfm?doid=1328438.1328483},
volume = {43},
year = {2008}
}
@inproceedings{Viera2014,
address = {New York, NY, USA},
author = {Viera, Marcos and Swierstra, S Doaitse},
booktitle = {Proceedings of the 25th Symposium on Implementation and Application of Functional Languages},
doi = {10.1145/2620678.2620686},
file = {:Users/elegios/Documents/Mendeley Desktop/Viera, Swierstra - 2014 - First Class Syntax, Semantics, and Their Composition.pdf:pdf},
isbn = {978-1-4503-2988-0},
keywords = {Attribute Grammars,Extensible Languages,Haskell,Typed Grammars,Typed Transformations},
pages = {73:73----73:84},
publisher = {ACM},
series = {IFL '13},
title = {{First Class Syntax, Semantics, and Their Composition}},
year = {2014}
}
@article{Parr:2014:ALP:2714064.2660202,
address = {New York, NY, USA},
author = {Parr, Terence and Harwell, Sam and Fisher, Kathleen},
doi = {10.1145/2714064.2660202},
file = {:Users/elegios/Documents/Mendeley Desktop/Parr, Harwell, Fisher - 2014 - Adaptive LL() Parsing The Power of Dynamic Analysis.pdf:pdf},
isbn = {9781450325851},
issn = {0362-1340},
journal = {SIGPLAN Not.},
keywords = {all(*),augmented transition networks,dfa,gll,glr,grammar,ll(*),nondeterministic parsing,peg},
month = {oct},
number = {10},
pages = {579--598},
publisher = {ACM},
title = {{Adaptive LL(*) Parsing: The Power of Dynamic Analysis}},
url = {http://doi.acm.org/10.1145/2714064.2660202},
volume = {49},
year = {2014}
}
@inproceedings{Parr:2011:LFA:1993498.1993548,
address = {New York, NY, USA},
author = {Parr, Terence and Fisher, Kathleen},
booktitle = {Proceedings of the 32Nd ACM SIGPLAN Conference on Programming Language Design and Implementation},
doi = {10.1145/1993498.1993548},
file = {:Users/elegios/Documents/Mendeley Desktop/Parr, Fisher - 2011 - LL() The Foundation of the ANTLR Parser Generator.pdf:pdf},
isbn = {978-1-4503-0663-8},
keywords = {augmented transition networks,backtracking,context-sensitive parsing,deterministic finite automata,glr,memoization,nondeterministic parsing,peg,semantic predicates,subset construction,syntactic predicates},
pages = {425--436},
publisher = {ACM},
series = {PLDI '11},
title = {{LL(*): The Foundation of the ANTLR Parser Generator}},
url = {http://doi.acm.org/10.1145/1993498.1993548},
year = {2011}
}
@inproceedings{Lorenzen:2016:STS:2837614.2837644,
address = {New York, NY, USA},
author = {Lorenzen, Florian and Erdweg, Sebastian},
booktitle = {Proceedings of the 43rd Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
doi = {10.1145/2837614.2837644},
file = {:Users/elegios/Documents/Mendeley Desktop/Lorenzen, Erdweg - 2016 - Sound Type-dependent Syntactic Language Extension.pdf:pdf},
isbn = {978-1-4503-3549-2},
keywords = {Language extensibility,automatic verification,macros,metaprogramming,type soundness,type-dependent desugaring},
pages = {204--216},
publisher = {ACM},
series = {POPL '16},
title = {{Sound Type-dependent Syntactic Language Extension}},
url = {http://doi.acm.org/10.1145/2837614.2837644},
year = {2016}
}
@article{lorenzen2013modular,
abstract = {Language extensions introduce high-level programming constructs that protect programmers from low-level details and repetitive tasks. For such an abstraction barrier to be sustainable, it is important that no errors are reported in terms of generated code. A typical strategy is to check the original user code prior to translation into a low-level encoding, applying the assumption that the translation does not introduce new errors. Unfortunately, such assumption is untenable in general, but in particular in the context of extensible programming languages, such as Racket or SugarJ, that allow regular programmers to define language extensions. In this paper, we present a formalism for building and automatically verifying the type-soundness of syntactic language extensions. To build a type-sound language extension with our formalism, a developer declares an extended syntax, type rules for the extended syntax, and translation rules into the (possibly further extended) base language. Our formalism then validates that the user-defined type rules are sufficient to guarantee that the code generated by the translation rules cannot contain any type errors. This effectively ensures that an initial type check prior to translation precludes type errors in generated code. We have implemented a core system in PLT Redex and we have developed a syntactically extensible variant of System Fw that we extend with let notation, monadic do blocks, and algebraic data types. Our formalism verifies the soundness of each extension automatically.},
author = {Lorenzen, Florian and Erdweg, Sebastian},
file = {:Users/elegios/Documents/Mendeley Desktop/Lorenzen, Erdweg - 2013 - Modular and automated type-soundness verification for language extensions.pdf:pdf},
journal = {ACM SIGPLAN Notices},
keywords = {SugarJ,automatic verification,language extensibility,macros,metaprogramming,type soundness},
number = {9},
pages = {331--342},
publisher = {ACM},
title = {{Modular and automated type-soundness verification for language extensions}},
volume = {48},
year = {2013}
}
@article{Ganz2001,
abstract = {With few exceptions, macros have traditionally been viewed as operations on syntax trees or even on plain strings. This view makes macros seem ad hoc, and is at odds with two desirable features of contemporary typed functional languages: static typing and static scoping. At a deeper level, there is a need for a simple, usable semantics for macros. This paper argues that these problems can be addressed by formally viewing macros as multi-stage computations. This view eliminates the need for freshness conditions and tests on variable names, and provides a compositional interpretation that can serve as a basis for designing a sound type system for languages supporting macros, or even for compilation. To illustrate our approach, we develop and present MacroML, an extension of ML that supports inlining, recursive macros, and the definition of new binding constructs. The latter is subtle, and is the most novel addition in a statically typed setting. The semantics of a core subset of MacroML is given by an interpretation into MetaML, a statically-typed multi-stage programming language. It is then easy to show that MacroML is stage- and type-safe: macro expansion does not depend on runtime evaluation, and both stages do not "go wrong.},
author = {Ganz, Steven E and Sabry, Amr and Taha, Walid},
doi = {10.1145/507546.507646},
file = {:Users/elegios/Documents/Mendeley Desktop/Ganz, Sabry, Taha - 2001 - Macros as multi-stage computations type-safe, generative, binding macros in MacroML.pdf:pdf},
isbn = {1581134150},
issn = {0362-1340},
journal = {ACM SIGPLAN Notices},
number = {June 2014},
pages = {74--85},
title = {{Macros as multi-stage computations: type-safe, generative, binding macros in MacroML}},
url = {http://delivery.acm.org/10.1145/510000/507646/p74-ganz.pdf?key1=507646{\&}key2=0290402031{\&}coll=DL{\&}dl=ACM{\&}ip=68.164.219.101{\&}CFID=15142910{\&}CFTOKEN=34701950{\%}5Cnhttp://portal.acm.org/citation.cfm?id=507646{\%}5Cnhttp://www.cs.rice.edu/{~}taha/publications/conference/},
volume = {36},
year = {2001}
}
@article{Adams2015,
abstract = {Hygiene is an essential aspect of Scheme's macro system that prevents unintended variable capture. However, previous work on hygiene has focused on algorithmic implementation rather than precise, mathematical definition of what constitutes hygiene. This is in stark contrast with lexical scope, alpha-equivalence and capture-avoiding substitution, which also deal with preventing unintended variable capture but have widely applicable and well-understood mathematical definitions. This paper presents such a precise, mathematical definition of hygiene. It reviews various kinds of hygiene violation and presents examples of how they occur. From these examples, we develop a practical algorithm for hygienic macro expansion. We then present algorithm-independent, mathematical criteria for whether a macro expansion algorithm is hygienic. This characterization corresponds closely to existing hygiene algorithms and sheds light on aspects of hygiene that are usually overlooked in informal definitions.},
author = {Adams, Michael D},
doi = {10.1145/2676726.2677013},
file = {:Users/elegios/Documents/Mendeley Desktop/Adams - 2015 - Towards the Essence of Hygiene.pdf:pdf},
isbn = {9781450333009},
issn = {15232867},
journal = {Proceedings of the 42nd Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages - POPL '15},
keywords = {hygiene,macros,nominal logic},
number = {January},
pages = {457--469},
title = {{Towards the Essence of Hygiene}},
url = {http://dl.acm.org/citation.cfm?id=2676726.2677013},
year = {2015}
}
@article{Culpepper2010,
abstract = {Existing macro systems force programmers to make a choice between clarity of specification and robustness. If they choose clarity, they must forgo validating significant parts of the specification and thus produce low-quality language extensions. If they choose robustness, they must write in a style that mingles the implementation with the specification and therefore obscures the latter. This paper introduces a new language for writing macros. With the new macro system, programmers naturally write robust language extensions using easy-to-understand specifications. The system translates these specifications into validators that detect misuses - including violations of context-sensitive constraints - and automatically synthesize appropriate feedback, eliminating the need for ad hoc validation code.},
author = {Culpepper, Ryan and Felleisen, Matthias},
doi = {10.1145/1932681.1863577},
file = {:Users/elegios/Documents/Mendeley Desktop/Culpepper, Felleisen - 2010 - Fortifying macros.pdf:pdf},
isbn = {9781605587943},
issn = {03621340},
journal = {ACM SIGPLAN Notices},
number = {9},
pages = {235},
pmid = {15064132439662487881},
title = {{Fortifying macros}},
url = {http://portal.acm.org/citation.cfm?doid=1932681.1863577},
volume = {45},
year = {2010}
}
@article{Burmako2013,
abstract = {Compile-time metaprogramming has been proven immensely useful enabling programming techniques such as language virtualization, embedding of external DSLs, self-optimization, and boilerplate generation amongst many others. In the recent production release of Scala 2.10 we have introduced macros, an experimental facility which gives its users compile-time metaprogramming powers. Alongside of the mainline release of Scala Macros, we have also intro-duced other macro flavors, which provide their users with different interfaces and capabilities for interacting with the Scala compiler. In this paper, we show how the rich syntax and static types of Scala synergize with macros, through a number of real case studies using our macros (some of which are production systems) such as language virtualization, type providers, materialization of type class instances, type-level programming, and embedding of external DSLs. We explore how macros enable new and unique ways to use pre-existing language features such as implicits, dynamics, annotations, string interpolation and others, showing along the way how these synergies open up new ways of dealing with software development challenges.},
author = {Burmako, E},
doi = {10.1145/2489837.2489840},
file = {:Users/elegios/Documents/Mendeley Desktop/Burmako - 2013 - Scala macros Let our powers combine!On how rich syntax and static types work with metaprogramming.pdf:pdf},
isbn = {9781450320641},
journal = {Proceedings of the 4th Workshop on Scala, SCALA 2013},
title = {{Scala macros: Let our powers combine!:On how rich syntax and static types work with metaprogramming}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84882408923{\&}partnerID=40{\&}md5=af4401c8928ff226aa9ee762443ec9f9},
year = {2013}
}
@inproceedings{leijen1999domain,
author = {Leijen, Daan and Meijer, Erik},
booktitle = {ACM Sigplan Notices},
file = {:Users/elegios/Documents/Mendeley Desktop/Leijen, Meijer - 1999 - Domain Specific Embedded Compilers.pdf:pdf},
number = {1},
organization = {ACM},
pages = {109--122},
title = {{Domain Specific Embedded Compilers}},
volume = {35},
year = {1999}
}
@techreport{plt-tr1,
annote = {$\backslash$url{\{}https://racket-lang.org/tr1/{\}}},
author = {Flatt, Matthew and PLT},
institution = {PLT Design Inc.},
number = {PLT-TR-2010-1},
title = {{Reference: Racket}},
year = {2010}
}
@article{Flatt2009,
author = {Flatt, Matthew and Barzilay, Eli and Findler, Robert Bruce},
doi = {10.1145/1596550.1596569},
file = {:Users/elegios/Documents/Mendeley Desktop/Flatt, Barzilay, Findler - 2009 - Scribble.pdf:pdf},
isbn = {9781605583327},
journal = {Proceedings of the 14th ACM SIGPLAN international conference on Functional programming - ICFP '09},
number = {September},
pages = {109},
title = {{Scribble}},
url = {http://dl.acm.org/citation.cfm?doid=1596550.1596569},
year = {2009}
}
@article{Flatt2012,
abstract = {Racket (formerly PLT Scheme) is a large language that is built mostly within itself. Unlike the usual approach taken by non-Lisp languages, the self-hosting of Racket is not a matter of bootstrapping one implementation through a previous implementation, but instead a matter of building a tower of languages and libraries via macros. The upper layers of the tower include a class system, a component system, pedagogic variants of Scheme, a statically typed dialect of Scheme, and more. The demands of this language-construction effort require a macro system that is substantially more expressive than previous macro systems. In particular, while conventional Scheme macro systems handle stand-alone syntactic forms adequately, they provide weak support for macros that share information or macros that use existing syntactic forms in new contexts. This paper describes and models novel features of the Racket macro system, including support for general compile-time bindings, sub-form expansion and analysis, and environment management. The presentation assumes a basic familiarity with Lisp-style macros, and it takes for granted the need for macros that respect lexical scope. The model, however, strips away the pattern and template system that is normally associated with Scheme macros, isolating a core that is simpler, that can support pattern and template forms themselves as macros, and that generalizes naturally to Rackets other extensions.},
author = {Flatt, Matthew and Culpepper, Ryan and Darais, David and Findler, Robert Bruce},
doi = {10.1017/S0956796812000093},
file = {:Users/elegios/Documents/Mendeley Desktop/Flatt et al. - 2012 - Macros that Work Together.pdf:pdf},
issn = {0956-7968},
journal = {Journal of Functional Programming},
number = {02},
pages = {181--216},
title = {{Macros that Work Together}},
volume = {22},
year = {2012}
}
@article{Tobin-Hochstadt2011,
abstract = {Programming language design benefits from constructs for extending the syntax and semantics of a host language. While C's string-based macros empower programmers to introduce notational shorthands, the parser-level macros of Lisp encourage experimentation with domain-specific languages. The Scheme programming language improves on Lisp with macros that respect lexical scope. The design of Racket---a descendant of Scheme---goes even further with the introduction of a full-fledged interface to the static semantics of the language. A Racket extension programmer can thus add constructs that are indistinguishable from "native" notation, large and complex embedded domain-specific languages, and even optimizing transformations for the compiler backend. This power to experiment with language design has been used to create a series of sub-languages for programming with first-class classes and modules, numerous languages for implementing the Racket system, and the creation of a complete and fully integrated typed sister language to Racket's untyped base language. This paper explains Racket's language extension API via an implementation of a small typed sister language. The new language provides a rich type system that accommodates the idioms of untyped Racket. Furthermore, modules in this typed language can safely exchange values with untyped modules. Last but not least, the implementation includes a type-based optimizer that achieves promising speedups. Although these extensions are complex, their Racket implementation is just a library, like any other library, requiring no changes to the Racket implementation.},
author = {Tobin-Hochstadt, Sam and St-Amour, Vincent and Culpepper, Ryan and Flatt, Matthew and Felleisen, Matthias},
doi = {10.1145/2345156.1993514},
file = {:Users/elegios/Documents/Mendeley Desktop/Tobin-Hochstadt et al. - 2011 - Languages as libraries.pdf:pdf},
isbn = {9781450306638},
issn = {03621340},
journal = {Proceedings of the 32nd ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI'11)},
number = {1993},
pages = {132--141},
title = {{Languages as libraries}},
year = {2011}
}
@article{Dolan2016,
abstract = {Type inference gives programmers the benefit of static, compile-time type checking without the cost of manually specifying types, and has long been a standard feature of functional programming languages. However, it has proven difficult to integrate type inference with subtyping, since the unification engine at the core of classical type inference accepts only equations, not subtyping constraints. This thesis presents a type system combining ML-style parametric polymorphism and subtyping, with type inference, principal types, and decidable type subsumption. Type inference is based on biunification, an analogue of unification that works with subtyping constraints. Making this possible are several contributions, beginning with the notion of an “extensible” type system, in which an open world of types is assumed, so that no typeable program becomes untypeable by the addition of new types to the language. While previous formulations of subtyping fail to be extensible, this thesis shows that adopting a more algebraic approach can remedy this. Using such an approach, this thesis develops the theory of biunification, shows how it is used to infer types, and shows how it can be efficiently implemented, exploiting deep connections between the algebra of regular languages and polymorphic subtyping.},
author = {Dolan, Stephen},
file = {:Users/elegios/Documents/Mendeley Desktop/Dolan - 2016 - Algebraic Subtyping (2016) pdf.pdf:pdf},
number = {September},
title = {{Algebraic Subtyping (2016) [pdf]}},
url = {https://www.cl.cam.ac.uk/{~}sd601/thesis.pdf},
year = {2016}
}
@techreport{carlson1993experiment,
author = {Carlson, William E and Hudak, Paul and Jones, M},
institution = {Research Report 1031, Department of Computer Science, Yale University},
title = {{An experiment using Haskell to prototype “geometric region servers” for Navy command and control}},
year = {1993}
}
@article{Herman2010,
abstract = {We present the $\lambda$m-calculus, a semantics for a language of hygienic macros with a non-trivial theory. Unlike Scheme, where programs must be macro- expanded to be analyzed, our semantics admits reasoning about programs as they appear to programmers. Our contributions include a semantics of hygienic macro expansion, a formal definition of $\alpha$-equivalence that is independent of expansion, and a proof that expansion preserves $\alpha$-equivalence. The key technical component of our language is a type system similar to Culpepper and Felleisens shape types, but with the novel contribution of binding signature types, which specify the bindings and scope of a macros arguments.},
author = {Herman, David and Wand, Mitchell},
doi = {10.1007/978-3-540-78739-6_4},
file = {:Users/elegios/Documents/Mendeley Desktop/Herman, Wand - 2010 - A Theory of Typed Hygienic Macros.pdf:pdf},
isbn = {3540787380},
issn = {03029743},
journal = {Proceedings of the 17th European Symposium on Programming},
pages = {48},
title = {{A Theory of Typed Hygienic Macros}},
url = {http://www.springerlink.com/index/V03K0734Q7217R35.pdf},
volume = {4960},
year = {2010}
}
@article{Sujeeth2013,
abstract = {Domain-specific languages provide a promising path to automatically compile high-level code to parallel, heterogeneous, and distributed hardware. However, in practice high performance DSLs still require considerable software expertise to develop and force users into tool-chains that hinder prototyping and debugging. To address these problems, we present Forge, a new meta DSL for declaratively specifying high performance embedded DSLs. Forge provides DSL authors with high-level abstractions (e.g., data structures, parallel patterns, effects) for specifying their DSL in a way that permits high performance. From this high-level specification, Forge automatically generates both a na{\"{i}}ve Scala library implementation of the DSL and a high performance version using the Delite DSL framework. Users of a Forge-generated DSL can prototype their application using the library version, and then switch to the Delite version to run on multicore CPUs, GPUs, and clusters without changing the application code. Forge-generated Delite DSLs perform within 2x of hand-optimized C++ and up to 40x better than Spark, an alternative high-level distributed programming environment. Compared to a manually implemented Delite DSL, Forge provides a factor of 3-6x reduction in lines of code and does not sacrifice any performance. Furthermore, Forge specifications can be generated from existing Scala libraries, are easy to maintain, shield DSL developers from changes in the Delite framework, and enable DSLs to be retargeted to other frameworks transparently.},
author = {Sujeeth, Arvind K and Gibbons, Austin and Brown, Kevin J and Lee, HyoukJoong and Rompf, Tiark and Odersky, Martin and Olukotun, Kunle},
doi = {10.1145/2637365.2517220},
file = {:Users/elegios/Documents/Mendeley Desktop/Sujeeth et al. - 2013 - Forge Generating a High Performance DSL Implementation from a Declarative Specification.pdf:pdf},
isbn = {9781450323734},
issn = {0362-1340},
journal = {SIGPLAN Not.},
keywords = {code generation,domain-specific languages,multi-stage programming,parallel programming},
number = {3},
pages = {145--154},
title = {{Forge: Generating a High Performance DSL Implementation from a Declarative Specification}},
url = {http://doi.acm.org/10.1145/2637365.2517220},
volume = {49},
year = {2013}
}
@article{CARETTE2009,
abstract = {We have built the first family of tagless interpretations for a higher-order typed object language in a typed metalanguage (Haskell or ML) that require no dependent types, generalized algebraic data types, or postprocessing to eliminate tags. The statically type-preserving interpretations include an evaluator, a compiler (or staged evaluator), a partial evaluator, and call-by-name and call-by-value continuation-passing style (CPS) transformers. Our principal technique is to encode de Bruijn or higher-order abstract syntax using combinator functions rather than data constructors. In other words, we represent object terms not in an initial algebra but using the coalgebraic structure of the $\lambda$-calculus. Our representation also simulates inductive maps from types to types, which are required for typed partial evaluation and CPS transformations. Our encoding of an object term abstracts uniformly over the family of ways to interpret it, yet statically assures that the interpreters never get stuck. This family of interpreters thus demonstrates again that it is useful to abstract over higher-kinded types.},
author = {CARETTE, JACQUES and KISELYOV, OLEG and SHAN, CHUNG-CHIEH},
doi = {10.1017/S0956796809007205},
file = {:Users/elegios/Documents/Mendeley Desktop/CARETTE, KISELYOV, SHAN - 2009 - Finally tagless, partially evaluated Tagless staged interpreters for simpler typed languages.pdf:pdf},
isbn = {3540766367,},
issn = {0956-7968},
journal = {Journal of Functional Programming},
number = {05},
pages = {509},
title = {{Finally tagless, partially evaluated: Tagless staged interpreters for simpler typed languages}},
url = {http://www.journals.cambridge.org/abstract{\_}S0956796809007205},
volume = {19},
year = {2009}
}
@article{Chang2017,
abstract = {We present TURNSTILE, a metalanguage for creating typed embedded languages. To implement the type system, pro-grammers write type checking rules resembling traditional judgment syntax. To implement the semantics, they incorpo-rate elaborations into these rules. TURNSTILE critically de-pends on the idea of linguistic reuse. It exploits a macro sys-tem in a novel way to simultaneously type check and rewrite a surface program into a target language. Reusing a macro system also yields modular implementations whose rules may be mixed and matched to create other languages. Com-bined with typical compiler and runtime reuse, TURNSTILE produces performant typed languages with little effort.},
author = {Chang, Stephen and Knauth, Alex and Greenman, Ben},
doi = {10.1145/3009837.3009886},
file = {:Users/elegios/Documents/Mendeley Desktop/Chang, Knauth, Greenman - 2017 - Type systems as macros.pdf:pdf},
isbn = {9781450346603},
issn = {07308566},
journal = {Proceedings of the 44th ACM SIGPLAN Symposium on Principles of Programming Languages  - POPL 2017},
keywords = {macros,type systems,typed embedded dsls},
pages = {694--705},
title = {{Type systems as macros}},
url = {http://dl.acm.org/citation.cfm?doid=3009837.3009886},
year = {2017}
}
@article{Rompf2012,
abstract = {Programs expressed in a high-level programming language need to be translated to a low-level machine dialect for execution. This translation is usually accomplished by a compiler, which is able to translate any legal program to equivalent low-level code. But for individual source programs, automatic translation does not always deliver good results: Software engineering practice demands generalization and abstraction, whereas high performance demands spe- cialization and concretization. These goals are at odds, and compilers can only rarely translate expressive high-level programs to modern hardware platforms in a way that makes best use of the available resources. Explicit program generation is a promising alternative to fully automatic translation. Instead of writing down the program and relying on a compiler for translation, developers write a program generator, which produces a specialized, efficient, low-level program as its output. However, developing high-quality program generators requires a very large effort that is often hard to amortize. In this thesis, we propose a hybrid design: Integrate compilers into programs so that programs can take control of the translation process, but rely on libraries of common compiler functionality for help. We present Lightweight Modular Staging (LMS), a generative programming approach that lowers the development effort significantly. LMS combines program generator logic with the generated code in a single program, using only types to distinguish the two stages of execution. Through extensive use of component technology, LMS makes a reusable and extensible compiler framework available at the library level, allowing programmers to tightly integrate domain-specific abstractions and optimizations into the generation process, with common generic optimizations provided by the framework. Compared to previous work on program generation, a key aspect of our design is the use of staging not only as a front-end, but also as a way to implement internal compiler passes and optimizations, many of which can be combined into powerful joint simplification passes. LMS is well suited to develop embedded domain specific languages (DSLs) and has been used to develop powerful performance-oriented DSLs for demanding domains such as ma- chine learning, with code generation for heterogeneous platforms including GPUs. LMS has also been used to generate SQL for embedded database queries and JavaScript for web applications.},
author = {Rompf, Tiark},
doi = {10.5075/epfl-thesis-5456},
file = {:Users/elegios/Documents/Mendeley Desktop/Rompf - 2012 - Lightweight Modular Staging and Embedded Compilers Abstraction Without regret for High-Level High-Performance Programm.pdf:pdf},
number = {2012},
pages = {191},
title = {{Lightweight Modular Staging and Embedded Compilers: Abstraction Without regret for High-Level High-Performance Programm}},
volume = {5456},
year = {2012}
}
@article{VanderWalt2015,
abstract = {Writing a platform for reactive applications which enforces operational constraints is difficult, and has been approached in various ways. In this experience report, we detail an approach using an embedded DSL which can be used to specify the structure and permissions of a program in a given application domain. Once the developer has specified which components an application will consist of, and which permissions each one needs, the specification itself evaluates to a new, tailored, language. The final implementation of the application is then written in this specialised environment where precisely the API calls associated with the permissions which have been granted, are made available. Our prototype platform targets the domain of mobile computing, and is implemented using Racket. It demonstrates resource access control (e.g., camera, address book, etc.) and tries to prevent leaking of private data. Racket is shown to be an extremely effective platform for designing new programming languages and their run-time libraries. We demonstrate that this approach allows reuse of an inter-component communication layer, is convenient for the application developer because it provides high-level building blocks to structure the application, and provides increased control to the platform owner, preventing certain classes of errors by the developer.},
archivePrefix = {arXiv},
arxivId = {1504.02001},
author = {van der Walt, Paul},
eprint = {1504.02001},
file = {:Users/elegios/Documents/Mendeley Desktop/van der Walt - 2015 - Constraining application behaviour by generating languages.pdf:pdf},
title = {{Constraining application behaviour by generating languages}},
url = {http://arxiv.org/abs/1504.02001},
year = {2015}
}
@article{Augustsson2008,
author = {Augustsson, Lennart and Mansell, Howard and Sittampalam, Ganesh},
doi = {10.1145/1411204.1411236},
file = {:Users/elegios/Documents/Mendeley Desktop/Augustsson, Mansell, Sittampalam - 2008 - Paradise.pdf:pdf},
isbn = {9781595939197},
journal = {Proceeding of the 13th ACM SIGPLAN international conference on Functional programming - ICFP '08},
number = {September 2008},
pages = {225},
title = {{Paradise}},
url = {http://portal.acm.org/citation.cfm?doid=1411204.1411236},
year = {2008}
}
@article{Gill,
author = {Gill, B Y Andy and Many, There A R E},
file = {:Users/elegios/Documents/Mendeley Desktop/Gill, Many - Unknown - Domain- Specific Languages and Code Synthesis Using Haskell.pdf:pdf},
pages = {42--49},
title = {{Domain- Specific Languages and Code Synthesis Using Haskell}}
}
@article{Elloitt2003,
abstract = {Abstract Functional languages are particularly well-suited to the interpretive implementations of Domain-Specific Embedded Languages (DSELs). We describe an implemented technique for producing optimizing compilers for DSELs, based on Kamin's idea of DSELs for program generation. The technique uses a data type of syntax for basic types, a set of smart constructors that perform rewriting over those types, some code motion transformations, and a back-end code generator. Domain-specific optimization results from chains of domain-independent rewrites on basic types. New DSELs are defined directly in terms of the basic syntactic types, plus host language functions and tuples. This definition style makes compilers easy to write and, in fact, almost identical to the simplest embedded interpreters. We illustrate this technique with a language Pan for the computationally intensive domain of image synthesis and manipulation. PapersGroups},
author = {Elloitt, Conal and Finne, Sigbj{\o}rn and de Moor, Oege},
doi = {10.1017/S0956796802004574},
file = {:Users/elegios/Documents/Mendeley Desktop/Elloitt, Finne, de Moor - 2003 - Compiling Embedded Languages.pdf:pdf},
isbn = {978-3-540-41054-6},
issn = {09567968},
journal = {Journal of Functional Programming},
number = {3},
pages = {455--481},
title = {{Compiling Embedded Languages}},
volume = {13},
year = {2003}
}
@article{Svenningsson2013,
abstract = {When compiling embedded languages it is natural to use an abstract syntax tree to represent programs. This is known as a deep embedding and it is a rather cumbersome technique compared to other forms of embedding, typically leading to more code and being harder to extend. In shallow embeddings, language constructs are mapped directly to their semantics which yields more flexible and succinct implementations. But shallow embeddings are not well-suited for compiling embedded languages. We present a technique to combine deep and shal- low embedding in the context of compiling embedded languages in order to provide the benefits of both techniques. In particular it helps keeping the deep embedding small and it makes extending the embedded language much easier. Our technique also has some unexpected but welcome knock-on effects. It provides fusion of functions to remove intermediate results for free without any additional effort. It also helps to give the embedded language a more natural programming interface.},
author = {Svenningsson, Josef and Axelsson, Emil},
doi = {10.1007/978-3-642-40447-4_2},
file = {:Users/elegios/Documents/Mendeley Desktop/Svenningsson, Axelsson - 2013 - Combining deep and shallow embedding for EDSL.pdf:pdf},
isbn = {9783642404467},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {21--36},
title = {{Combining deep and shallow embedding for EDSL}},
volume = {7829 LNCS},
year = {2013}
}
@article{Herman2008,
abstract = {We present the $\lambda$m-calculus, a semantics for a language of hygienic macros with a non-trivial theory. Unlike Scheme, where programs must be macro- expanded to be analyzed, our semantics admits reasoning about programs as they appear to programmers. Our contributions include a semantics of hygienic macro expansion, a formal definition of $\alpha$-equivalence that is independent of expansion, and a proof that expansion preserves $\alpha$-equivalence. The key technical component of our language is a type system similar to Culpepper and Felleisens shape types, but with the novel contribution of binding signature types, which specify the bindings and scope of a macros arguments.},
author = {Herman, David and Wand, Mitchell},
doi = {10.1007/978-3-540-78739-6_4},
file = {:Users/elegios/Documents/Mendeley Desktop/Herman, Wand - 2008 - A theory of hygienic macros.pdf:pdf},
isbn = {3540787380},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {48--62},
title = {{A theory of hygienic macros}},
volume = {4960 LNCS},
year = {2008}
}
@article{Czarnecki2004,
abstract = {A wide range of domain-specific languages (DSLs) has been implemented successfully by embedding them in general purpose languages. This paper reviews embedding, and summarizes how two alternative techniques staged interpreters and templates can be used to overcome the limitations of embedding. Both techniques involve a form of generative programming. The paper reviews and compares three programming languages that have special support for generative programming. Two of these languages (MetaOCaml and Template Haskell) are research languages, while the third (C++) is already in wide industrial use. The paper identifies several dimensions that can serve as a basis for comparing generative languages.},
author = {Czarnecki, K and O'Donnell, J and Striegnitz, J and Taha, W},
doi = {10.1007/b98156},
file = {:Users/elegios/Documents/Mendeley Desktop/Czarnecki et al. - 2004 - Domain-Specific Program Generation.pdf:pdf},
isbn = {978-3-540-22119-7},
issn = {03029743},
journal = {Domain-Specific Program Generation},
keywords = {macro},
pages = {51--72},
title = {{Domain-Specific Program Generation}},
url = {http://link.springer.com/10.1007/b98156},
volume = {3016},
year = {2004}
}
@article{Ghosh2011,
abstract = {One of the main reasons why software projects fail is the lack of communication between the business users, who actually know the problem domain, and the developers who design and implement the software model. Business users understand the domain terminology, and they speak a vocabulary that may be quite alien to the software people; its no wonder that the communication model can break down right at the beginning of the project life cycle. A DSL (domain-specific language)1,3 bridges the semantic gap between business users and developers by encouraging better collaboration through shared vocabulary. The domain model that the developers build uses the same terminologies as the business. The abstractions that the DSL offers match the syntax and semantics of the problem domain. As a result, users can get involved in verifying business rules throughout the life cycle of the project. This article describes the role that a DSL plays in modeling expressive business rules. It starts with the basics of domain modeling and then introduces DSLs, which are classified according to implementation techniques. The article then explains in detail the design and implementation of an embedded DSL from the domain of securities trading},
author = {Ghosh, Debasish},
doi = {10.1145/1965724.1965740},
file = {:Users/elegios/Documents/Mendeley Desktop/Ghosh - 2011 - DSL for the uninitiated.pdf:pdf},
issn = {00010782},
journal = {Communications of the ACM},
number = {7},
pages = {44},
title = {{DSL for the uninitiated}},
url = {http://portal.acm.org/citation.cfm?doid=1965724.1965740},
volume = {54},
year = {2011}
}
@book{Overgaard2004,
author = {{\"{O}}vergaard, Gunnar and Palmkvist, Karin},
edition = {1},
isbn = {0131451340},
publisher = {Addison-Wesley Professional},
title = {{Use Cases: Patterns and Blueprints}},
year = {2004}
}
@misc{TheMendeleySupportTeam2011,
abstract = {A quick introduction to Mendeley. Learn how Mendeley creates your personal digital library, how to organize and annotate documents, how to collaborate and share with colleagues, and how to generate citations and bibliographies.},
address = {London},
author = {{The Mendeley Support Team}},
booktitle = {Mendeley Desktop},
file = {:Users/elegios/Documents/Mendeley Desktop/The Mendeley Support Team - 2011 - Getting Started with Mendeley.pdf:pdf},
keywords = {Mendeley,how-to,user manual},
pages = {1--16},
publisher = {Mendeley Ltd.},
title = {{Getting Started with Mendeley}},
url = {http://www.mendeley.com},
year = {2011}
}
