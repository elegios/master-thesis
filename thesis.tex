\documentclass{kththesis}

\usepackage{blindtext} % This is just to get some nonsense text in this template, can be safely removed

\usepackage{csquotes} % Recommended by biblatex
\usepackage{biblatex}
\addbibresource{references.bib} % The file containing our references, in BibTeX format


\title{This is the English title}
\alttitle{Detta är den svenska översättningen av titeln}
\author{Osquar Student}
\email{osquar@kth.se}
\supervisor{Lotta Larsson}
\examiner{Lennart Bladgren}
\programme{Master in Computer Science}
\school{School of Computer Science and Communication}
\date{\today}


\begin{document}

% Frontmatter includes the titlepage, abstracts and table-of-contents
\frontmatter

\titlepage

\begin{abstract}
  English abstract goes here.

  \blindtext
\end{abstract}


\begin{otherlanguage}{swedish}
  \begin{abstract}
    Träutensilierna i ett tryckeri äro ingalunda en oviktig faktor,
    för trevnadens, ordningens och ekonomiens upprätthållande, och
    dock är det icke sällan som sorgliga erfarenheter göras på grund
    af det oförstånd med hvilket kaster, formbräden och regaler
    tillverkas och försäljas Kaster som äro dåligt hopkomna och af
    otillräckligt.
  \end{abstract}
\end{otherlanguage}


\tableofcontents


% Mainmatter is where the actual contents of the thesis goes
\mainmatter


\chapter{Introduction}

The implementation of a programming language --- be it an interpreter or a compiler --- tends to be divided into phases, each dealing with their own aspect of the language. For example, a parser details the syntax of the language, while name resolution handles names, scoping, and namespaces. A type checker details part of the semantics, how different language constructions can be combined. This means that the implementation of any single language construction is spread throughout the language implementation, necessitating it be considered as a whole. Adding a new construction requires changes in many places.

Some languages include methods to add new constructions within the language itself, without extending the implementation; one important one being macros \cite{plt-tr1,Hickey2008,Matsakis2014}. Macros add new constructions by defining them in terms of previously existing constructions. Evaluation proceeds by expanding each macro, possibly recursively, until only base language constructions remain, at which point the program can be evaluated normally. However, if a macro is improperly used or poorly implemented any error produced will generally refer to the fully expanded program, rather than the program as it was written. The macro abstraction is thus leaky, and its usability suffers from it.

Additionally, most macro systems are constrained by the syntax of the base language; no new syntax can be introduced. This can for example be seen in Lisp and its descendants, such as Scheme, Racket, and Clojure.

\section{Objective}

This project explores a macro system without these two limitations, where the macros can be seen as true parts of a language even in terms of errors, and where they can introduce new syntax, allowing them to define entire languages. Much work has been done on each of these two things separately, but their intersection is less explored.

There is some exploration however, but it tends to treat languages as the base unit of composition, i.e., languages are made up of languages, as opposed to the individual constructions. This project instead considers the constructions as the base unit of composition, e.g., allowing a new language to cherrypick constructions from previous languages, instead of having to build on full languages.

\section{Research Question}

Can languages be defined modularly on the level of individual constructions, both syntactically and semantically, while preserving abstraction and allowing composition?

\chapter{Methods}

\chapter{Related Work}

This section describes various related work, either solving the same problem with a different method, or solving some sub-problem. Most of the description is oriented around the capabilities of the various methods, with extra detail depending on the methods similarity to this thesis.

\section{SDF}

\textcite{Heering1989} introduce the syntax definition formalism SDF, a method for declaratively defining syntax, including lexical syntax, context free syntax, and various disambiguation methods.

\section{Layout-sensitive SDF}

\textcite{Erdweg2013} extend SDF to handle layout-sensitive grammars in a declarative manner through annotations in each production restricting their relative positions. To achieve this they determine a limited subset of possible layout restrictions that are sufficient to describe the rules of most layout-sensitive languages.

\section{$\lambda_m$}

$\lambda_m$ \cite{Herman2010} is an extension of lambda calculus with macros and macro type signatures. These signatures describe the structure of macro arguments and results, including binding structure, and form an inspirational basis to the approach taken by this project in regard to hygiene and name binding.

Some notable differences exist however:
\begin{itemize}
  \item $\lambda_m$ macros can only affect bindings within themselves, a natural consequence of lambda calculus lacking constructions where bindings are not nested, e.g., a local variable in C can be used for the remainder of the scope, not only in some sub-expression, which is the case for a let-expression. This project handles such binding structures, which imposes some additional restrictions on what the implementation of a macro can do.
  \item The macro type signatures in this project are never fully explicit, they appear spread out through each macro definition amongst other aspects of the definition. $\lambda_m$ in contrast uses a complete type signature for each macro.
\end{itemize}

$\lambda_m$ also introduces definitions of $\alpha$-equivalence and hygiene that do not depend on macro expansion and also place focus on allowing reasoning about unexpanded programs.

\section{Romeo}

\textcite{Stansifer2014} introduce Romeo, a language extending $\lambda_m$ by providing full syntax manipulation capabilities while still retaining hygiene. $\lambda_m$ is limited to pattern matching and replacing, while Romeo can manipulate terms as data.

\section{Copper and Silver}

Copper \cite{VanWyk2007} defines a grammar and a lexical scanner that works in tandem, where the scanner only returns tokens that the grammar defines as valid next tokens given the current state of the parse. It uses a modified LR parsing algorithm. The combination manages to parse more languages, since the scanner can work unambiguously in more cases. Silver \cite{VanWyk2010} uses attribute grammars to specify modular language extensions on some host language, along with guarantees on some of their behaviour under composition \cite{Kaminski2017}. Silver uses Copper for grammar specification.

\section{SoundX}

\textcite{Lorenzen2016} introduce SoundX, a system for specifying syntax and type rules for a base language, and then language extensions through rewritings (macros). Each rewriting also has specified type rules, detailing what is required for a successful type derivation. Through these it can be statically checked that assuming there is a derivation of the original code, then there will be a derivation in the base language of the rewriting, i.e. it can be statically checked that the rewriting is correct as written, and each use can be checked for correctness without actually performing the rewriting. SDF is used for the syntactic specification of languages and language extensions.

SoundX can technically fail during rewriting. Rewriting is done on derivation trees, and the same construct may appear in multiple premises. If those appearances rewrite into different, incompatible, desugarings the process will fail.

\printbibliography[heading=bibintoc] % Print the bibliography (and make it appear in the table of contents)

\appendix

\chapter{Unnecessary Appended Material}

\end{document}
