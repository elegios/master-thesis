\documentclass{kththesis}

\usepackage{blindtext} % This is just to get some nonsense text in this template, can be safely removed

\usepackage{minted}

\usepackage{csquotes} % Recommended by biblatex
\usepackage{biblatex}
\addbibresource{references.bib} % The file containing our references, in BibTeX format

\title{Compositional Programming Language Design}
\alttitle{Detta är den svenska översättningen av titeln}
\author{Viktor Palmkvist}
\email{vipa@kth.se}
\supervisor{David Broman}
\examiner{Mads Dam}
\programme{Master in Computer Science}
\school{School of Computer Science and Communication}
\date{\today}


\begin{document}

% Frontmatter includes the titlepage, abstracts and table-of-contents
\frontmatter

\titlepage

\begin{abstract}
TBW
\end{abstract}


\begin{otherlanguage}{swedish}
\begin{abstract}
Kommer så småningom
\end{abstract}
\end{otherlanguage}


\tableofcontents


% Mainmatter is where the actual contents of the thesis goes
\mainmatter


\chapter{Introduction} \label{sec:introduction}

The implementation of a programming language---be it an interpreter or a compiler---tends to be divided into phases, each dealing with their own aspect of the language. For example, a parser details the syntax of the language, while name resolution handles names, scoping, and namespaces. A type checker details part of the semantics, how different language constructions can be combined. This means that the implementation of any single language construction is spread throughout the language implementation, necessitating it be considered as a whole. Adding a new construction requires changes in many places.

Some languages include methods to add new constructions within the language itself, without extending the implementation; one important one being macros \cite{plt-tr1,Hickey2008,Matsakis2014}. Macros add new constructions by defining them in terms of previously existing constructions. Evaluation proceeds by expanding each macro, possibly recursively, until only base language constructions remain, at which point the program can be evaluated normally.

When looking at macros in languages that are commonly used today a few problems remain however. This thesis will focus on two broad categories of such problems: abstraction (see section \ref{sec:problem-abstraction}) and syntax (see section \ref{sec:problem-syntax}). These problems have been solved separately (see sections \ref{sec:abstraction-solutions} and \ref{sec:syntax-solutions}) as well as in conjunction (see section \ref{sec:full-solutions}). This thesis falls into the second camp and largely addresses both problems, with a new set of trade-offs and a different unit of composition. See section \ref{sec:solution-overview} for an overview and section \ref{sec:thesis-solution} for more details.

\section{Problems of Abstraction} \label{sec:problem-abstraction}

The abstractions provided by macros can easily become leaky abstractions without special care.

\subsection{Name Capture}

A naive macro expander using textual replacement will introduce accidental name capture. For example, given the following macro (using Racket \cite{plt-tr1} syntax) intended to calculate $2a + b$ while computing $a$ only once:

\begin{minted}{racket}
(define-syntax-rule (double-add a b)
  (let ([x a])
    (+ x x b)))
\end{minted}

The following expression will exhibit accidental name capture when macro expansion uses pure textual replacement:

\begin{minted}{racket}
(let ([x 2])
  (double-add 1 x))
; expands to:
(let ([x 2])
  (let ([x 1])
    (double-add x x x)))
; which evaluates to
3
; while our intended semantics would evaluate to:
4
\end{minted}

Notable here is that the above would not produce an error of any kind, the result would simply be silently wrong.

Most macro systems will avoid this problem through various forms of rewriting or more complicated forms of name resolution (e.g. \cite{Flatt:2016:BSS:2837614.2837620} TODO: references), a notable exception being the C preprocessor that makes no such attempt.

\subsection{Errors after Expansion}

In some cases the fully expanded code is incorrect, either because the macro was poorly implemented, or because it was used improperly. For example:

\begin{minted}{racket}
(define-syntax-rule (new-let x e body)
  (let ([x e])
    body))

(new-let 2 x
  (+ 1 x))
\end{minted}

Here we define a new binding construction, but misuse it; the identifier and the value are switched. The macro expansion will succeed and produce the code below, but at that point an error message will be produced about improper use of \mintinline{racket}{let}, even though \mintinline{racket}{let} never occurs in the original code.

\begin{minted}{racket}
(let ([2 x])
  (+ 1 x))
\end{minted}

The error exposes the implementation of the macro. The generated code may be introduced through several layers of macro expansion and can be quite complicated, making the connection between the error message and the actual error even less clear.

In a statically typed language this problem has an additional form: type errors after macro expansion.

\section{Problems of Syntax} \label{sec:problem-syntax}

One advantage of macros is their ability to essentially introduce syntactic sugar to a language at a user level. Despite this most commonly used macro systems place some fairly strict limits on the newly introduced syntax. For example, a C preprocessor macro must be an identifier, possibly followed by an argument list, and a lisp macro must be a list of valid forms started by a symbol.

Such restrictions simplify parsing the language, since it ensures the grammar is fixed and cannot be changed during parsing.

\section{Contributions}

This thesis contributes the following:

\begin{itemize}
  \item A method of specifying the syntax, binding semantics and implementation of a language construction (macro) in a singular location (sections \ref{sec:design-syntax}, \ref{sec:design-bindings} and \ref{sec:design-implementation}).
  \item Proof that macro expansion using the above method terminates, given a finite input (section \ref{sec:proof-termination}).
  \item Proof that macro expansion does not introduce any binding errors (alternatively preservation of $\alpha$-equivalence) (section \ref{sec:proof-no-errors}).
  \item An implementation of a non-trivial subset of JavaScript/Lua (section \ref{sec:imperative-eval}) to evaluate the method's suitability in modeling a typical imperative language.
  \item An implementation of a non-trivial subset of OCaml (section \ref{sec:functional-eval}) to evaluate the method's suitability in modeling a typical functional language, focusing on pattern matching.
\end{itemize}

\chapter{Design}

\section{Design Goals}

\section{Syntax} \label{sec:design-syntax}

\section{Bindings} \label{sec:design-bindings}

\section{Implementation} \label{sec:design-implementation}

\section{Proof of Termination} \label{sec:proof-termination}

\section{Proof of Soundness} \label{sec:proof-no-errors}

\chapter{Evaluation}

\section{An Imperative Language} \label{sec:imperative-eval}

\section{A Functional Language} \label{sec:functional-eval}

\chapter{Related Work}

The related work is separated roughly based on the degree to which they solve the two problems introduced in section \ref{introduction}: solutions for abstraction problems, solutions for syntax problems, and solutions that address both problems. These solutions deal with various forms of macro systems, except for those only concerning syntax; they deal with parsing extensible syntax and largely do not concern themselves with the semantics of what is being parsed.

\section{Abstraction Solutions} \label{sec:abstraction-solutions}

Lisps have long had macro systems that do not introduce accidental name capture, mostly through renaming (TODO: references). The latest iteration of Racket's \cite{plt-tr1} macro expander instead achieves binding hygiene by using sets of scopes \cite{Flatt:2016:BSS:2837614.2837620}. Somewhat simplified, a set of scopes is attached to each identifier, namely the scopes that contain it. To find the binding referred to by an identifier with set $s_i$, find the binding with set $s_b \subseteq s_i$ such that for all other sets $s'_b \subseteq s_i$ attached to binders, $s'_b \subset s_b$, i.e. $s_b$ is the largest subset of $s_i$. The authors report the implementation as simpler to follow, and while ambiguous references are possible they do not appear in practice.

$\lambda_m$ \cite{Herman2010} takes a different route and is an extension of the lambda calculus with macros and macro type signatures. These signatures describe the structure of macro arguments and results, including binding structure, and form an inspirational basis to the approach taken by this thesis in regard to hygiene and name binding.

Some notable differences exist however:
\begin{itemize}
  \item Bindings in $\lambda_m$ macros are always nested, in the sense that bindings are never available outside of the macro that introduced them. In contrast, consider a local variable in e.g. C:
  \begin{minted}{c}
  int foo = 4;
  printf("foo: %d\n", foo);
  \end{minted}
  The local variable \mintinline{c}{foo} is available for the remainder of the scope, potentially long after the declaration has ended. This thesis handles both kinds of binding.
  \item TODO: EBNF, recursion and union types
\end{itemize}

In addition, $\lambda_m$ introduces definitions of $\alpha$-equivalence and hygiene that do not depend on macro expansion and places focus on allowing reasoning about unexpanded programs.

Romeo \cite{Stansifer2014} continue the path of typed macros but extends it to allow procedural macros, as opposed to the pattern matching and replacing of $\lambda_m$.

\section{Syntax Solutions} \label{sec:syntax-solutions}

The syntax definition formalism SDF \cite{Heering1989} is a system with a combined notation for lexical and context-free grammar, along with a parser. Productions are listed individually, allowing non-terminals to be spread across files in a very similar fashion to the syntax constructions of this thesis. SDF also uses associativity annotations for operators instead of necessitating a manual rewriting of the grammar.

A specification in SDF is used to generate a lexical grammar and a context-free grammar, both of which are then used for the actual parsing. The productions in the specification also double to describe an abstract syntax tree, which is the end result.

SDF has also been extended to handle layout-sensitive grammars \cite{Erdweg2013} through extra annotations, thus retaining the declarative nature of a grammar.

\textcite{Silkensen2013} instead consider the problem of combining already constructed grammars in a scalable way. The main observation they use is that most domain specific languages deal with values of different types. With this in mind the different grammars can use these types, for example using non-terminals such as \mintinline{text}{Matrix} instead of \mintinline{text}{Expression}. Additionally, if identifiers can be specified to have a specific type (e.g. \mintinline{text}{Matrix}) they can be used as islands in island parsing. By using these two things the authors present a parsing algorithm that needs to examine far fewer possible parsings, even in the presence of many DSLs. The precise scalability claim can be found in the paper.

\section{Combined Solutions} \label{sec:full-solutions}

SoundX \cite{Lorenzen2016} is a system for specifying extensible languages. It uses SDF (see section \ref{sec:syntax-solutions}) to specify syntax and adds type rules and type judgements. A language extension is specified as a set of rewritings (macros) and type rules for the rewritings. Macros in SoundX are checked to guarantee that they preserve abstraction on a type level, i.e. they introduce no type errors during rewriting. Similarly, code can be type checked without performing rewriting.

The system works through a rewriting of derivation trees, not pure syntax, thus macros have access to not only types explicit in a program but also derived types.

Copper \cite{VanWyk2007} and Silver \cite{VanWyk2010} together form a system for extensible languages based on attribute grammars. Copper defines a grammar and a lexical scanner that work in tandem, where the scanner only returns tokens that the grammar defines as valid next tokens given the current state of the parse. The combination mananges to parse more languages, since the scanner can work unambiguously in more cases. Silver allows modular language extensions on some host language, all of them defined using attribute grammars, along with some guarantees on their behaviour under composition \cite{Kaminski2017}.

\chapter{Results and Discussion}

\section{Results}

\section{Discussion}

\section{Conclusion}

\printbibliography[heading=bibintoc]

% \appendix

% \chapter{Unnecessary Appended Material}

\end{document}
